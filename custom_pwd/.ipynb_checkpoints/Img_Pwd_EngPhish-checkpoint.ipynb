{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is avaliable\n"
     ]
    }
   ],
   "source": [
    "import keras,os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dropout\n",
    "print(\"GPU is\",\"avaliable\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"not available\")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image-based PWD training on EngPhish, refer to the middle column of Table XIII and Table XIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eng_root = \"../data/engphish/engphish_screen/\"\n",
    "eng_folder=os.listdir(eng_root)\n",
    "\n",
    " \n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for label in os.listdir(eng_root):\n",
    "  #print('label is',label)\n",
    "  label_path = os.path.join(eng_root, label)\n",
    "  if os.path.isdir(label_path):\n",
    "      for image_file in os.listdir(label_path):\n",
    "          image_path = os.path.join(label_path, image_file)\n",
    "          image_paths.append(image_path)\n",
    "          #print('image_path is',image_path)\n",
    "          labels.append(label)\n",
    "train_image_paths, test_image_paths, train_labels, test_labels = train_test_split(\n",
    "  image_paths, labels, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "train_df = pd.DataFrame({'paths': train_image_paths, 'labels': train_labels})\n",
    "test_df = pd.DataFrame({'paths': test_image_paths, 'labels': test_labels})\n",
    "\n",
    "\n",
    "\n",
    "image_width = 224\n",
    "image_height = 224\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "  rescale=1./255,   \n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "  dataframe=train_df,\n",
    "  x_col=\"paths\",\n",
    "  y_col=\"labels\",\n",
    "  target_size=(image_width, image_height),\n",
    "  batch_size=batch_size,\n",
    "  class_mode='categorical',#binary',\n",
    "  shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = train_datagen.flow_from_dataframe(\n",
    "  dataframe=test_df,\n",
    "  x_col=\"paths\",\n",
    "  y_col=\"labels\",\n",
    "  target_size=(image_width, image_height),\n",
    "  batch_size=batch_size,\n",
    "  class_mode='categorical',#binary',\n",
    "  shuffle=True\n",
    ")\n",
    "\n",
    "#vgg16\n",
    "\n",
    "def create_model2():\n",
    "    model_vgg16 = Sequential()\n",
    "    model_vgg16.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"valid\", activation=\"relu\"))\n",
    "    model_vgg16.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"valid\", activation=\"relu\"))\n",
    "    model_vgg16.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "    model_vgg16.add(Dropout(0.25))\n",
    "    model_vgg16.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"valid\", activation=\"relu\"))\n",
    "    model_vgg16.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"valid\", activation=\"relu\"))\n",
    "    model_vgg16.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "    model_vgg16.add(Dropout(0.25))\n",
    "    model_vgg16.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"valid\", activation=\"relu\"))\n",
    "    model_vgg16.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"valid\", activation=\"relu\"))\n",
    "    model_vgg16.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"valid\", activation=\"relu\"))\n",
    "    model_vgg16.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "    model_vgg16.add(Dropout(0.25))\n",
    "    model_vgg16.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"valid\", activation=\"relu\"))\n",
    "    model_vgg16.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"valid\", activation=\"relu\"))\n",
    "    model_vgg16.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"valid\", activation=\"relu\"))\n",
    "    model_vgg16.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "    model_vgg16.add(Dropout(0.25))\n",
    "    model_vgg16.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"valid\", activation=\"relu\"))\n",
    "    model_vgg16.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"valid\", activation=\"relu\"))\n",
    "    model_vgg16.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"valid\", activation=\"relu\"))\n",
    "    model_vgg16.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "    model_vgg16.add(Dropout(0.25))\n",
    "    model_vgg16.add(Flatten())\n",
    "    model_vgg16.add(Dense(units=4096,activation=\"relu\",use_bias=False))\n",
    "    model_vgg16.add(Dropout(0.5))\n",
    "    model_vgg16.add(Dense(units=4096,activation=\"relu\",use_bias=False))\n",
    "    model_vgg16.add(Dropout(0.5))\n",
    "    model_vgg16.add(Dense(2,activation=\"softmax\",use_bias=False)) #\"softmax\"\n",
    "    model_vgg16.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])#sparse_categorical_crossentropy\n",
    "    return model_vgg16\n",
    "\n",
    "#cnn model\n",
    "model_cnn = tf.keras.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (224, 224, 3)),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "\n",
    "model_cnn.compile(optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "cnn_start=time.time()\n",
    "model_cnn.fit(train_generator, epochs=20)\n",
    "cnn_end=time.time()\n",
    "cnn_train_time=cnn_end-cnn_start\n",
    "\n",
    "cnn_test_st=time.time()\n",
    "predictions = model_cnn.predict(test_generator)\n",
    "cnn_test_en=time.time()\n",
    "cnn_test_time=cnn_test_en-cnn_test_st\n",
    "#predictions =loaded_model.predict(test_generator)\n",
    "\n",
    "binary_predictions = tf.argmax(predictions, axis=1)\n",
    "ground_truth_labels = test_df.labels\n",
    "label_mapping = {'benign': 0, 'phish': 1}\n",
    "\n",
    "ground_truth = [label_mapping[label] for label in ground_truth_labels]\n",
    "\n",
    "cm = confusion_matrix(ground_truth, binary_predictions)\n",
    "\n",
    "# Extract True Positives (TP), True Negatives (TN), False Positives (FP), False Negatives (FN) from the confusion matrix\n",
    "TN = cm[0][0]\n",
    "FP = cm[0][1]\n",
    "FN = cm[1][0]\n",
    "TP = cm[1][1]\n",
    "\n",
    "# Calculate True Positive Rate (TPR) and True Negative Rate (TNR)\n",
    "TPR = TP / (TP + FN)\n",
    "TNR = TN / (TN + FP)\n",
    "FPR = FP / (FP + TN)\n",
    "FNR = FN / (FN + TP)\n",
    "#print('TPR is %.3f, TNR is %.3f'%(TPR,TNR))\n",
    "print('FPR is %.3f, FNR is %.3f'%(FPR,FNR))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
